{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Structures- Space and Time Complexity\n",
    "> Observing the time complexity of different algorithms\n",
    "- toc: true\n",
    "- categories: []\n",
    "- type: pbl\n",
    "- week: 27"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Space and Time Complexity\n",
    "> Space complexity refers to the amount of memory used by an algorithm to complete its execution, as a function of the size of the input. The space complexity of an algorithm can be affected by various factors such as the size of the input data, the data structures used in the algorithm, the number and size of temporary variables, and the recursion depth. Time complexity refers to the amount of time required by an algorithm to run as the input size grows. It is usually measured in terms of the \"Big O\" notation, which describes the upper bound of an algorithm's time complexity."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Why do you think a programmer should care about space and time complexity?\n",
    "- A programmer should care about space and time complexity because these are both two major factors that can effect the efficiency and readability of code. The code that can take the least amount of time and fill the least space will be the most efficient when it comes to larger scale projects."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at our lassen volcano example from the data compression tech talk. The first code block is the original image. In the second code block, change the baseWidth to rescale the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from pathlib import Path \n",
    "\n",
    "# prepares a series of images\n",
    "def image_data(path=Path(\"images/\"), images=None):  # path of static images is defaulted\n",
    "    for image in images:\n",
    "        # File to open\n",
    "        image['filename'] = path / image['file']  # file with path\n",
    "    return images\n",
    "\n",
    "def image_display(images):\n",
    "    for image in images:  \n",
    "        display(Image(filename=image['filename']))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    lassen_volcano = image_data(images=[{'source': \"Peter Carolin\", 'label': \"Lassen Volcano\", 'file': \"lassen-volcano.jpg\"}])\n",
    "    image_display(lassen_volcano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "from pathlib import Path \n",
    "from PIL import Image as pilImage \n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "# prepares a series of images\n",
    "def image_data(path=Path(\"images/\"), images=None):  # path of static images is defaulted\n",
    "    for image in images:\n",
    "        # File to open\n",
    "        image['filename'] = path / image['file']  # file with path\n",
    "    return images\n",
    "\n",
    "def scale_image(img):\n",
    "    #baseWidth = 625\n",
    "    #baseWidth = 1250\n",
    "    #baseWidth = 2500\n",
    "    baseWidth = 5000 # see the effect of doubling or halfing the baseWidth \n",
    "    #baseWidth = 10000 \n",
    "    #baseWidth = 20000\n",
    "    #baseWidth = 40000\n",
    "    scalePercent = (baseWidth/float(img.size[0]))\n",
    "    scaleHeight = int((float(img.size[1])*float(scalePercent)))\n",
    "    scale = (baseWidth, scaleHeight)\n",
    "    return img.resize(scale)\n",
    "\n",
    "def image_to_base64(img, format):\n",
    "    with BytesIO() as buffer:\n",
    "        img.save(buffer, format)\n",
    "        return base64.b64encode(buffer.getvalue()).decode()\n",
    "    \n",
    "def image_management(image):  # path of static images is defaulted        \n",
    "    # Image open return PIL image object\n",
    "    img = pilImage.open(image['filename'])\n",
    "    \n",
    "    # Python Image Library operations\n",
    "    image['format'] = img.format\n",
    "    image['mode'] = img.mode\n",
    "    image['size'] = img.size\n",
    "    image['width'], image['height'] = img.size\n",
    "    image['pixels'] = image['width'] * image['height']\n",
    "    # Scale the Image\n",
    "    img = scale_image(img)\n",
    "    image['pil'] = img\n",
    "    image['scaled_size'] = img.size\n",
    "    image['scaled_width'], image['scaled_height'] = img.size\n",
    "    image['scaled_pixels'] = image['scaled_width'] * image['scaled_height']\n",
    "    # Scaled HTML\n",
    "    image['html'] = '<img src=\"data:image/png;base64,%s\">' % image_to_base64(image['pil'], image['format'])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Use numpy to concatenate two arrays\n",
    "    images = image_data(images = [{'source': \"Peter Carolin\", 'label': \"Lassen Volcano\", 'file': \"lassen-volcano.jpg\"}])\n",
    "    \n",
    "    # Display meta data, scaled view, and grey scale for each image\n",
    "    for image in images:\n",
    "        image_management(image)\n",
    "        print(\"---- meta data -----\")\n",
    "        print(image['label'])\n",
    "        print(image['source'])\n",
    "        print(image['format'])\n",
    "        print(image['mode'])\n",
    "        print(\"Original size: \", image['size'], \" pixels: \", f\"{image['pixels']:,}\")\n",
    "        print(\"Scaled size: \", image['scaled_size'], \" pixels: \", f\"{image['scaled_pixels']:,}\")\n",
    "        \n",
    "        print(\"-- original image --\")\n",
    "        display(HTML(image['html']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big O Notation\n",
    "- Constant O(1)\n",
    "- Linear O(n)\n",
    "- Quadratic O(n^2) \n",
    "- Logarithmic O(logn)\n",
    "- Exponential (O(2^n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list called numbers with 1,000 numbers in it\n",
    "numbers = list(range(1000))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant O(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time\n",
    "> An example of a constant time algorithm is accessing a specific element in an array. It does not matter how large the array is, accessing an element in the array takes the same amount of time. Therefore, the time complexity of this operation is constant, denoted by O(1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263\n"
     ]
    }
   ],
   "source": [
    "print(numbers[263])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Space\n",
    "> This function takes two integer inputs and returns their sum. The function does not create any additional data structures or variables that are dependent on the input size, so its space complexity is constant, or O(1). Regardless of how large the input integers are, the function will always require the same amount of memory to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum(a, b): \n",
    "  return a + b;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear O(n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time\n",
    "> An example of a linear time algorithm is traversing a list or an array. When the size of the list or array increases, the time taken to traverse it also increases linearly with the size. Hence, the time complexity of this operation is O(n), where n is the size of the list or array being traversed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterates through the list \n",
    "for i in numbers:\n",
    "    print(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Space\n",
    "> This function takes a list of elements arr as input and returns a new list with the elements in reverse order. The function creates a new list reversed_arr of the same size as arr to store the reversed elements. The size of reversed_arr depends on the size of the input arr, so the space complexity of this function is O(n). As the input size increases, the amount of memory required to execute the function also increases linearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_list(arr):\n",
    "    n = len(arr)\n",
    "    reversed_arr = [None] * n\n",
    "    for i in range(n):\n",
    "        reversed_arr[n-i-1] = arr[i]\n",
    "    return reversed_arr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadratic O(n^2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time\n",
    "> An example of a quadratic time algorithm is nested loops. When there are two nested loops that both iterate over the same collection, the time taken to complete the algorithm grows quadratically with the size of the collection. Hence, the time complexity of this operation is O(n^2), where n is the size of the collection being iterated over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in numbers:\n",
    "    for j in numbers:\n",
    "        print(i,j)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Space\n",
    "> This function takes two matrices matrix1 and matrix2 as input and returns their product as a new matrix. The function creates a new matrix result with dimensions m by n to store the product of the input matrices. The size of result depends on the size of the input matrices, so the space complexity of this function is O(n^2). As the size of the input matrices increases, the amount of memory required to execute the function also increases quadratically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18, 28], [18, 28]]\n"
     ]
    }
   ],
   "source": [
    "def multiply_matrices(matrix1, matrix2):\n",
    "    m = len(matrix1) \n",
    "    n = len(matrix2[0])\n",
    "    result = [[0] * n] * m #this creates the new matrix based on the size of matrix 1 and 2\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            for k in range(len(matrix2)):\n",
    "                result[i][j] += matrix1[i][k] * matrix2[k][j]\n",
    "    return result\n",
    "\n",
    "print(multiply_matrices([[1,2],[3,4]], [[3,4],[1,2]]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logarithmic O(logn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time\n",
    "> An example of a log time algorithm is binary search. Binary search is an algorithm that searches for a specific element in a sorted list by repeatedly dividing the search interval in half. As a result, the time taken to complete the search grows logarithmically with the size of the list. Hence, the time complexity of this operation is O(log n), where n is the size of the list being searched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263\n"
     ]
    }
   ],
   "source": [
    "#function used to search for a target using a binary search\n",
    "def binary_search(arr, low, high, target):\n",
    "    while low <= high:\n",
    "        mid = (low + high) // 2\n",
    "        if arr[mid] == target:\n",
    "            return mid\n",
    "        elif arr[mid] < target:\n",
    "            low = mid + 1\n",
    "        else:\n",
    "            high = mid - 1\n",
    "\n",
    "target = 263\n",
    "result = binary_search(numbers, 0, len(numbers) - 1, target)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Space\n",
    "> The same algorithm above has a O(logn) space complexity. The function takes an array arr, its lower and upper bounds low and high, and a target value target. The function searches for target within the bounds of arr by recursively dividing the search space in half until the target is found or the search space is empty. The function does not create any new data structures that depend on the size of arr. Instead, the function uses the call stack to keep track of the recursive calls. Since the maximum depth of the recursive calls is O(logn), where n is the size of arr, the space complexity of this function is O(logn). As the size of arr increases, the amount of memory required to execute the function grows logarithmically."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exponential O(2^n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time\n",
    "> An example of an O(2^n) algorithm is the recursive implementation of the Fibonacci sequence. The Fibonacci sequence is a series of numbers where each number is the sum of the two preceding ones, starting from 0 and 1. The recursive implementation of the Fibonacci sequence calculates each number by recursively calling itself with the two preceding numbers until it reaches the base case (i.e., the first or second number in the sequence). The algorithm takes O(2^n) time in the worst case because it has to calculate each number in the sequence by making two recursive calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#recrursive function to calculate the fibonacci number at n\n",
    "def fibonacci(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    else:\n",
    "        return fibonacci(n-1) + fibonacci(n-2)\n",
    "\n",
    "print(fibonacci(3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Space\n",
    "> This function takes a set s as input and generates all possible subsets of s. The function does this by recursively generating the subsets of the set without the first element, and then adding the first element to each of those subsets to generate the subsets that include the first element. The function creates a new list for each recursive call that stores the subsets, and each element in the list is a new list that represents a subset. The number of subsets that can be generated from a set of size n is 2^n, so the space complexity of this function is O(2^n). As the size of the input set increases, the amount of memory required to execute the function grows exponentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_subsets(s):\n",
    "    if not s:\n",
    "        return [[]]\n",
    "    subsets = generate_subsets(s[1:])\n",
    "    return [[s[0]] + subset for subset in subsets] + subsets\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using the time library, we are able to see the difference in time it takes to calculate the fibonacci function above.\n",
    "- Based on what is known about the other time complexities, hypothesize the resulting elapsed time if the function is replaced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5702887\n",
      "Time taken: 1.314479112625122 seconds\n",
      "9227465\n",
      "Time taken: 2.0933010578155518 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "print(fibonacci(34))\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "print(\"Time taken:\", total_time, \"seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "print(fibonacci(35))\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "print(\"Time taken:\", total_time, \"seconds\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacks\n",
    "\n",
    "- Record your findings when testing the time elapsed of the different algorithms.\n",
    "    - \n",
    "    \n",
    "- Why is time and space complexity important when choosing an algorithm?\n",
    "    - A programmer should care about space and time complexity because these are both two major factors that can effect the efficiency and readability of code. The code that can take the least amount of time and fill the least space will be the most efficient when it comes to larger scale projects.\n",
    "\n",
    "- Should you always use a constant time algorithm / Should you never use an exponential time algorithm? Explain? \n",
    "    - No, it's not always necessary to use a constant time algorithm nor is it always bad to use an exponential time algorithm. The choice of algorithm depends on the specific problem you are trying to solve, the size of the input data, and the resources available to you. If you have a small input size and limited resources, a constant time algorithm might be the most efficient choice. But if your input size is large, it might not be possible to solve the problem with a constant time algorithm, and you might have to resort to an algorithm with higher time complexity, such as an exponential time algorithm.\n",
    "    - For example, in cryptography, brute force algorithms that try every possible key are often exponential time algorithms. While these algorithms are slow, they are still useful because the only known way to break the encryption is to try all possible keys. Similarly, in certain scientific simulations, it might be necessary to use an exponential time algorithm to model complex physical systems accurately.\n",
    "\n",
    "- What are some general patterns that you noticed to determine each algorithm's time and space complexity?\n",
    "    - Nested loops: If an algorithm contains one or more nested loops, the time complexity is typically O(n^2), O(n^3), or some other polynomial time complexity, where n is the size of the input data.\n",
    "    - Recursive calls: If an algorithm is recursive, the time complexity is often expressed using a recurrence relation. The complexity of a recursive algorithm is usually related to the number of recursive calls and the size of the data being processed.\n",
    "    - Sorting and searching: If an algorithm involves sorting or searching data, the time complexity is usually expressed in terms of the number of elements being sorted or searched. For example, quicksort and merge sort have a time complexity of O(n log n), while linear search has a time complexity of O(n).\n",
    "    - Data structures: If an algorithm uses data structures like arrays, lists, or trees, the space complexity is usually proportional to the size of the data being stored. For example, an algorithm that creates an array of size n has a space complexity of O(n).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we will go more in depth later, time complexity is a key concept that relates to the different sorting algorithms. Do some basic research on the different types of sorting algorithms and their time complexity.\n",
    "1. Bubble Sort: It is one of the simplest sorting algorithms, where each element is compared with its adjacent element and swapped if the adjacent element is greater. This process is repeated until the list is sorted. The time complexity of the bubble sort algorithm is O(n^2).\n",
    "\n",
    "2. Selection Sort: In this algorithm, the smallest element in the list is found and swapped with the first element. Then, the smallest element in the remaining list is found and swapped with the second element, and so on. The time complexity of the selection sort algorithm is O(n^2).\n",
    "\n",
    "3. Insertion Sort: This algorithm works by iterating through the list and inserting each element into its proper position in the sorted sub-list. The time complexity of the insertion sort algorithm is also O(n^2).\n",
    "\n",
    "4. Merge Sort: This algorithm divides the list into two halves recursively until each sub-list contains only one element. Then, the sub-lists are merged back together in sorted order. The time complexity of the merge sort algorithm is O(n log n).\n",
    "\n",
    "5. Quick Sort: It is a divide-and-conquer algorithm that selects a pivot element and partitions the list into two sub-lists, one with elements smaller than the pivot and the other with elements greater than the pivot. This process is repeated recursively until the list is sorted. The time complexity of the quick sort algorithm is O(n log n).\n",
    "\n",
    "6. Heap Sort: This algorithm sorts the elements by constructing a binary heap and repeatedly extracting the maximum element from the heap until the list is sorted. The time complexity of the heap sort algorithm is also O(n log n)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the Time and Space Complexity analysis questions linked below.\n",
    "[Practice](https://www.geeksforgeeks.org/practice-questions-time-complexity-analysis/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
